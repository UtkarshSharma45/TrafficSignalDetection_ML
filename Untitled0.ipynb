{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UtkarshSharma45/TrafficSignalDetection_ML/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkEI5SOkYDY1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U watermark"
      ],
      "metadata": {
        "id": "Bva-EMU-1hgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import PIL.Image as Image\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from glob import glob\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "VvJATkIe1-yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
        "!unzip -qq GTSRB_Final_Training_Images.zip"
      ],
      "metadata": {
        "id": "4KnXPW2r2L3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folders = sorted(glob('GTSRB/Final_Training/Images/*'))\n",
        "len(train_folders)"
      ],
      "metadata": {
        "id": "DkI8H6Fp2yHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(img_path, resize=True):\n",
        "  img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if resize:\n",
        "    img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "  return img\n",
        "\n",
        "def show_image(img_path):\n",
        "  img = load_image(img_path)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "\n",
        "def show_sign_grid(image_paths):\n",
        "  images = [load_image(img) for img in image_paths]\n",
        "  images = torch.as_tensor(images)\n",
        "  images = images.permute(0, 3, 1, 2)\n",
        "  grid_img = torchvision.utils.make_grid(images, nrow=11)\n",
        "  plt.figure(figsize=(24, 12))\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\n",
        "  plt.axis('off');\n",
        ""
      ],
      "metadata": {
        "id": "PItX3Sam3Kml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sign_grid(image_paths):\n",
        "  images = [load_image(img) for img in image_paths]\n",
        "  images = torch.as_tensor(images)\n",
        "  images = images.permute(0, 3, 1, 2)\n",
        "  grid_img = torchvision.utils.make_grid(images, nrow=11)\n",
        "  plt.figure(figsize=(24, 12))\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\n",
        "  plt.axis('off');"
      ],
      "metadata": {
        "id": "WKD24yI037r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images = [np.random.choice(glob(f'{tf}/*ppm')) for tf in train_folders]\n",
        "show_sign_grid(sample_images)"
      ],
      "metadata": {
        "id": "0KNiyUyY4FNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = glob(f'{train_folders[16]}/*ppm')[1]\n",
        "\n",
        "show_image(img_path)"
      ],
      "metadata": {
        "id": "RdubRInC4SD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['priority_road', 'give_way', 'stop', 'no_entry']\n",
        "\n",
        "class_indices = [12, 13, 14, 17]"
      ],
      "metadata": {
        "id": "vgVLQ1gu4ltd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf data\n",
        "\n",
        "DATA_DIR = Path('data')\n",
        "\n",
        "DATASETS = ['train', 'val', 'test']\n",
        "\n",
        "for ds in DATASETS:\n",
        "  for cls in class_names:\n",
        "    (DATA_DIR / ds / cls).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "e39iC_ha7KP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, cls_index in enumerate(class_indices):\n",
        "  image_paths = np.array(glob(f'{train_folders[cls_index]}/*.ppm'))\n",
        "  class_name = class_names[i]\n",
        "  print(f'{class_name}: {len(image_paths)}')\n",
        "  np.random.shuffle(image_paths)\n",
        "\n",
        "  ds_split = np.split(\n",
        "    image_paths,\n",
        "    indices_or_sections=[int(.8*len(image_paths)), int(.9*len(image_paths))]\n",
        "  )\n",
        "\n",
        "  dataset_data = zip(DATASETS, ds_split)\n",
        "\n",
        "  for ds, images in dataset_data:\n",
        "    for img_path in images:\n",
        "      shutil.copy(img_path, f'{DATA_DIR}/{ds}/{class_name}/')"
      ],
      "metadata": {
        "id": "ax_kLyIX7neP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_nums = [0.485, 0.456, 0.406]\n",
        "std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "transforms = {'train': T.Compose([\n",
        "  T.RandomResizedCrop(size=256),\n",
        "  T.RandomRotation(degrees=15),\n",
        "  T.RandomHorizontalFlip(),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean_nums, std_nums)\n",
        "]), 'val': T.Compose([\n",
        "  T.Resize(size=256),\n",
        "  T.CenterCrop(size=224),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean_nums, std_nums)\n",
        "]), 'test': T.Compose([\n",
        "  T.Resize(size=256),\n",
        "  T.CenterCrop(size=224),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean_nums, std_nums)\n",
        "]),\n",
        "}\n",
        ""
      ],
      "metadata": {
        "id": "bIK0G1uF7s3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {\n",
        "  d: ImageFolder(f'{DATA_DIR}/{d}', transforms[d]) for d in DATASETS\n",
        "}\n",
        "\n",
        "data_loaders = {\n",
        "  d: DataLoader(image_datasets[d], batch_size=4, shuffle=True, num_workers=4)\n",
        "  for d in DATASETS\n",
        "}"
      ],
      "metadata": {
        "id": "_rJkrKRt74KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {d: len(image_datasets[d]) for d in DATASETS}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "dataset_sizes"
      ],
      "metadata": {
        "id": "gSBuqTcfRviH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([mean_nums])\n",
        "  std = np.array([std_nums])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  plt.imshow(inp)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.axis('off')\n",
        "\n",
        "inputs, classes = next(iter(data_loaders['train']))\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "metadata": {
        "id": "gQ72WtCNR36b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(n_classes):\n",
        "  model = models.resnet34(pretrained=True)\n",
        "\n",
        "  n_features = model.fc.in_features\n",
        "  model.fc = nn.Linear(n_features, n_classes)\n",
        "\n",
        "  return model.to(device)"
      ],
      "metadata": {
        "id": "voYVT8tyR8Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = create_model(len(class_names))"
      ],
      "metadata": {
        "id": "jSu3y1FJSIwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for inputs, labels in data_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == labels)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "7Gxu6dQdSMsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in data_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "Gl5iMJwzSaro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data_loaders, dataset_sizes, device, n_epochs=3):\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "  history = defaultdict(list)\n",
        "  best_accuracy = 0\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{n_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "      model,\n",
        "      data_loaders['train'],\n",
        "      loss_fn,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler,\n",
        "      dataset_sizes['train']\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "      model,\n",
        "      data_loaders['val'],\n",
        "      loss_fn,\n",
        "      device,\n",
        "      dataset_sizes['val']\n",
        "    )\n",
        "\n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "      torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "      best_accuracy = val_acc\n",
        "    print(f'Best val accuracy: {best_accuracy}')\n",
        "\n",
        "    model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "thMZnYpzSezB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "base_model, history = train_model(base_model, data_loaders, dataset_sizes, device)"
      ],
      "metadata": {
        "id": "OUq0EsSCSrpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "  ax1.plot(history['train_loss'], label='train loss')\n",
        "  ax1.plot(history['val_loss'], label='validation loss')\n",
        "\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax1.set_ylim([-0.05, 1.05])\n",
        "  ax1.legend()\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "\n",
        "  ax2.plot(history['train_acc'], label='train accuracy')\n",
        "  ax2.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "  ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2.set_ylim([-0.05, 1.05])\n",
        "  ax2.legend()\n",
        "\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "\n",
        "  fig.suptitle('Training history')\n",
        ""
      ],
      "metadata": {
        "id": "PIw-aUU3TAiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "-BZYbMaZUNQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(model, class_names, n_images=6):\n",
        "  model = model.eval()\n",
        "  images_handeled = 0\n",
        "  plt.figure()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(data_loaders['test']):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      for j in range(inputs.shape[0]):\n",
        "        images_handeled += 1\n",
        "        ax = plt.subplot(2, n_images//2, images_handeled)\n",
        "        ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "        imshow(inputs.cpu().data[j])\n",
        "        ax.axis('off')\n",
        "\n",
        "        if images_handeled == n_images:\n",
        "          return"
      ],
      "metadata": {
        "id": "e6CnJ5hzUS-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_predictions(base_model, class_names, n_images=8)"
      ],
      "metadata": {
        "id": "MjPc603NXnBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4uxwAVOXqxM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}